{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "# local imports\n",
    "sys.path.append(r\"./utils\")\n",
    "from utils import utils\n",
    "\n",
    "random.seed(1234)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "COLAB = False\n",
    "SAMPLE = True\n",
    "DRY_RUN = False\n",
    "DATA_DIR = \"./data/full/\"\n",
    "GROUP_NAME = \"ethnicity\"\n",
    "MODEL_LIST = [\"NN\", \"LR\"]\n",
    "RESULTS_DIR = \".results/full/Ethnicity_Segments/\"\n",
    "RESULTS_STATS_FILENAME = GROUP_NAME + '.csv'\n",
    "RESULTS_MODEL_FILENAME_PREFIX = GROUP_NAME\n",
    "RESULTS = []\n",
    "\n",
    "MODEL_RESULTS = './results/Model results/'\n",
    "\n",
    "logger.debug(f\"Started the script for {GROUP_NAME}.\")\n",
    "\n",
    "if SAMPLE:\n",
    "  DATA_DIR = \"./data/sample/\"\n",
    "  RESULTS_DIR = \"./results/sample/Ethnicity_Segments/\"\n",
    "\n",
    "DATA_DROP_COLS = \\\n",
    "           ['Unnamed: 0', # index columns\n",
    "           'Unnamed: 0.1', # TODO: might need to change this for bigger dataset. ,\n",
    "              # 'pol',  # label column\n",
    "              'gender', # self reported and filtered already\n",
    "              # 'age', # self-reported  \n",
    "              'country', # self reported and filtered already\n",
    "              'userid', # index equivalent column \n",
    "              'pol_dat_us', # redundant columns with label\n",
    "              'pol_dat_ca', # redundant columns with label\n",
    "              'pol_dat_uk', # redundant columns with label\n",
    "              'pol_fb_us', # redundant columns with label\n",
    "              'database', # filtered already \n",
    "              'ethnicity.value' # filtered already\n",
    "              ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "    \n",
    "  #TODO: untested for COLAB == True, more might be needed here\n",
    "  DATA_DIR = \"/content/drive/Shareddrives/Facial Recognition/data/\""
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27282,
     "status": "ok",
     "timestamp": 1628212818347,
     "user": {
      "displayName": "Babandeep Singh",
      "photoUrl": "",
      "userId": "14171741079947983888"
     },
     "user_tz": -330
    },
    "id": "IGzNWI5xsm4D",
    "outputId": "da52c7bc-7ec7-4170-ca05-d01fe3edc9de"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read datasets\n",
    "\n",
    "folders = os.listdir(DATA_DIR)\n",
    "dataset_paths = []\n",
    "for folder in tqdm(folders):\n",
    "  logger.debug(f\"In folder {folder}.\")\n",
    "  csv_files = os.listdir(DATA_DIR + folder)\n",
    "  for csv in csv_files:\n",
    "    if '.csv' in csv:\n",
    "      logger.debug(DATA_DIR + folder + \"/\" + csv)\n",
    "      dataset_paths.append(DATA_DIR + folder + \"/\" + csv)\n",
    "\n",
    "\n",
    "print(len(dataset_paths))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "for dataset_path in dataset_paths:\n",
    "  data = pd.read_csv(dataset_path)\n",
    "  # Clean the data\n",
    "  try:\n",
    "    data = data.drop(DATA_DROP_COLS, axis=1)\n",
    "  except:\n",
    "    pass\n",
    "  data = utils.get_clean_data(data)\n",
    "  data_y = data['pol'].replace({\"liberal\": 1, \"conservative\": 0})\n",
    "  data = data.drop('pol', axis = 1)\n",
    "  all_features = data.columns\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size = 0.2, random_state=1234) \n",
    "  # TODO: check reproducibility of splits so that additional metrics computed post-hoc\n",
    "  # are consistent. See https://stackoverflow.com/questions/53182821/scikit-learn-train-test-split-not-reproducible\n",
    "\n",
    "  del data, data_y\n",
    "\n",
    "  # Define features for the various settings\n",
    "  image_cols = list(map(str, range(1, 2049)))\n",
    "  self_reported_cols = ['age']\n",
    "  image_and_self_reported_cols = image_cols + self_reported_cols\n",
    "  image_and_extracted_cols = [x for x in all_features if x not in self_reported_cols]\n",
    "  image_and_self_reported_and_extracted_cols = all_features\n",
    "\n",
    "  # which group it is being processed on \n",
    "  SEGMENT_NAME = utils.get_dataframe_name(dataset_path)\n",
    "  logger.debug(f\"Started the script for {SEGMENT_NAME}.\")\n",
    "\n",
    "  data_dict = {\n",
    "              \"Image Features\" : image_cols,\n",
    "              \"Image and Self Reported Features\" : image_and_self_reported_cols,\n",
    "              \"Image and Extracted Features\": image_and_extracted_cols,\n",
    "              \"Image, Self-reported and Extracted Features\": image_and_self_reported_and_extracted_cols\n",
    "              }\n",
    "\n",
    "  # Fit models\n",
    "  for data_name, data_set_features in tqdm(data_dict.items()):\n",
    "    for model_name in MODEL_LIST:\n",
    "      try:\n",
    "        logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: model training started.\")\n",
    "        auc, acc, model = utils.fit_and_get_metrics(model_name,\n",
    "                                                    X_train[data_set_features],\n",
    "                                                    y_train,\n",
    "                                                    X_test[data_set_features],\n",
    "                                                    y_test,\n",
    "                                                    dry_run = DRY_RUN)\n",
    "        utils.save_model(model, model_name, RESULTS_DIR \\\n",
    "                        + SEGMENT_NAME \\\n",
    "                        + \"_\" + model_name \\\n",
    "                        + \"_\" + data_name.replace(\" \",\"_\").replace(\",\",\"\").replace(\"-\",\"_\") \\\n",
    "                        + '.mdl')\n",
    "        RESULTS.append([SEGMENT_NAME, model_name, data_name, auc, acc])\n",
    "        logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: model training ended. AUC: {auc}, accuracy: {acc}\")\n",
    "      except:\n",
    "        logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: Error occured!\")\n",
    "\n",
    "utils.save_results(results_array = RESULTS, location = MODEL_RESULTS + RESULTS_STATS_FILENAME)\n",
    "logger.debug(f\"Script for {GROUP_NAME} finished.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ethnicity_segments_LR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "10e89b4373ca82b9aa008416dbc6678ec2573a3d463e333e4d350f38af34d33f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}