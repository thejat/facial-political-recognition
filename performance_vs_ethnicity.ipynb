{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(r\"./utils\")\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "SAMPLE_DATA = False\n",
    "DEBUG_MODEL = False\n",
    "\n",
    "GROUP_NAME = \"ethnicity_groups\"  # TODO : Changed this for ethnicity segments. \n",
    "MODEL_DICT = \\\n",
    "            {\"NN\": {'epochs': 25} , \n",
    "             \"LR\": {'max_iter': 100}\n",
    "            }\n",
    "SELF_REPORTED_COLS = \\\n",
    "           ['age',\n",
    "            # 'country_canada', \n",
    "            # 'country_united kingdom',\n",
    "            # 'country_united states',\n",
    "            # 'database_dating',\n",
    "            # 'database_fb',\n",
    "            # 'gender',\n",
    "           ]\n",
    "DATA_DROP_COLS = \\\n",
    "           ['Unnamed: 0', # index columns\n",
    "            # 'pol',  # label column\n",
    "            'gender', # self reported and filtered already\n",
    "            # 'age', # self-reported  \n",
    "            'country', # self reported and filtered already\n",
    "            'userid', # index equivalent column \n",
    "            'pol_dat_us', # redundant columns with label\n",
    "            'pol_dat_ca', # redundant columns with label\n",
    "            'pol_dat_uk', # redundant columns with label\n",
    "            'pol_fb_us', # redundant columns with label\n",
    "            'database', # filtered already \n",
    "            'ethnicity.value' # filtered already\n",
    "            ]\n",
    "RESULTS_COLS = \\\n",
    "            [\"Group Name\", \n",
    "             \"Model\", \n",
    "             \"Feature Set\", \n",
    "             \"Test AUC\", \n",
    "             \"Test Accuracy\",\n",
    "            ]\n",
    "DATA_DIR = \"./data/full/\"\n",
    "RESULTS_DIR = f\"./results/full/{GROUP_NAME}/\" #TODO: ensure that the folder exists\n",
    "RESULTS_STATS_FILENAME = GROUP_NAME + '.csv'\n",
    "RESULTS_MODEL_FILENAME_PREFIX = GROUP_NAME\n",
    "\n",
    "if SAMPLE_DATA:\n",
    "  DATA_DIR = \"./data/sample/\"\n",
    "  RESULTS_DIR = f\"./results/sample/{GROUP_NAME}/\"\n",
    "  ASSERT_DATA_SHAPE_0 = 31742\n",
    "  ASSERT_DATA_SHAPE_1 = 2092\n",
    "  DATA_DROP_COLS = DATA_DROP_COLS \\\n",
    "                  + ['Unnamed: 0.1'] #TODO: Regenerate sample with index=False and remove this\n",
    "\n",
    "if DEBUG_MODEL:\n",
    "  MODEL_DICT = \\\n",
    "            {\"NN\": {'epochs': 1} , \n",
    "             \"LR\": {'max_iter': 1}\n",
    "            }\n",
    "\n",
    "logger.debug(f\"Started the script for {GROUP_NAME}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "\n",
    "folders = os.listdir(DATA_DIR)\n",
    "dataset_paths = []\n",
    "for folder in tqdm(folders):\n",
    "  logger.debug(f\"In folder {folder}.\")\n",
    "  csv_files = os.listdir(DATA_DIR + folder)\n",
    "  for csv in csv_files:\n",
    "    if '.csv' in csv:\n",
    "      logger.debug(DATA_DIR + folder + \"/\" + csv)\n",
    "      dataset_paths.append(DATA_DIR + folder + \"/\" + csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "  data = pd.read_csv(dataset_path)\n",
    "  \n",
    "  # Clean the data\n",
    "  data = data.drop(DATA_DROP_COLS, axis=1)\n",
    "  data = utils.get_clean_data(data)\n",
    "  logger.debug(f\"Data size after cleaning is {data.shape}\")\n",
    "  data_y = data['pol'].replace({\"liberal\": 1, \"conservative\": 0})\n",
    "  data = data.drop('pol', axis = 1)\n",
    "  all_features = data.columns\n",
    "\n",
    "  # Split the data\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size = 0.2, random_state = 2021) \n",
    "  del data, data_y\n",
    "\n",
    "  # which group it is being processed on \n",
    "  SEGMENT_NAME = utils.get_dataframe_name(dataset_path)\n",
    "  logger.debug(f\"Started the script for {SEGMENT_NAME}.\")\n",
    "  \n",
    "  ## Define features for the various settings\n",
    "  image_cols = list(map(str, range(1, 2049)))\n",
    "  image_and_self_reported_cols = image_cols + SELF_REPORTED_COLS\n",
    "  image_and_extracted_cols = [x for x in all_features if x not in SELF_REPORTED_COLS]\n",
    "  image_and_self_reported_and_extracted_cols = all_features\n",
    "\n",
    "  data_dict = {\n",
    "                \"Image Features\" : image_cols,\n",
    "                \"Image and Self Reported Features\" : image_and_self_reported_cols,\n",
    "                \"Image and Extracted Features\": image_and_extracted_cols,\n",
    "                \"Image, Self-reported and Extracted Features\": image_and_self_reported_and_extracted_cols\n",
    "                }\n",
    "\n",
    "  if SEGMENT_NAME == \"canada_1_dating_india\": # this segment does not have any \"age\" values associated with it.\n",
    "    ## Define features for the various settings\n",
    "    image_cols = list(map(str, range(1, 2049)))\n",
    "    # image_and_self_reported_cols = image_cols + SELF_REPORTED_COLS \n",
    "    image_and_extracted_cols = [x for x in all_features if x not in SELF_REPORTED_COLS]\n",
    "    image_and_self_reported_and_extracted_cols = all_features\n",
    "\n",
    "  \n",
    "    data_dict = {\n",
    "                \"Image Features\" : image_cols,\n",
    "                # \"Image and Self Reported Features\" : image_and_self_reported_cols,\n",
    "                \"Image and Extracted Features\": image_and_extracted_cols,\n",
    "                \"Image, Self-reported and Extracted Features\": image_and_self_reported_and_extracted_cols\n",
    "                }\n",
    "\n",
    "\n",
    "  # Fit models and log results\n",
    "  for data_name, data_set_features in tqdm(data_dict.items()):\n",
    "    for model_name, model_params in MODEL_DICT.items():\n",
    "      try:\n",
    "        save_model_filepath = Path(RESULTS_DIR \\\n",
    "                        + SEGMENT_NAME\\\n",
    "                        + \"_\" + model_name \\\n",
    "                        + \"_\" + data_name.replace(\" \",\"_\").replace(\",\",\"\").replace(\"-\",\"_\") \\\n",
    "                        + '.mdl')\n",
    "\n",
    "        if save_model_filepath.is_file() or save_model_filepath.is_dir():\n",
    "          logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: model already exists.\")\n",
    "          model = utils.read_model(model_name, save_model_filepath)\n",
    "          logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: model read from disk.\")\n",
    "          \n",
    "        else:\n",
    "          logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: model training started.\")\n",
    "          model = utils.fit_model(model_name,\n",
    "                                X_train[data_set_features],\n",
    "                                y_train,\n",
    "                                model_params = model_params)\n",
    "\n",
    "          utils.save_model(model, model_name, save_model_filepath)\n",
    "          logger.debug(f\"{GROUP_NAME}, {model_name}, {data_name}: model training ended and model saved.\")\n",
    "        \n",
    "        auc, acc = utils.get_metrics(model_name,\n",
    "                                     model,\n",
    "                                     X_test[data_set_features],\n",
    "                                     y_test)\n",
    "                                     \n",
    "        results.append([SEGMENT_NAME, model_name, data_name, auc, acc])\n",
    "        logger.debug(f\"{SEGMENT_NAME}, {model_name}, {data_name}: model training ended. AUC: {auc}, accuracy: {acc}\")\n",
    "      \n",
    "      except Exception as error:\n",
    "        logger.exception(error)\n",
    "        logger.error(f\"{SEGMENT_NAME}, {model_name}, {data_name}: Error occured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results summary to disk\n",
    "\n",
    "save_results_filepath = Path(RESULTS_DIR + RESULTS_STATS_FILENAME)\n",
    "utils.save_results(results_array = results, \n",
    "                     location = save_results_filepath,\n",
    "                     columns = RESULTS_COLS)\n",
    "print(pd.DataFrame(results,columns = RESULTS_COLS))\n",
    "logger.debug(f\"Script for {GROUP_NAME} finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ethnicity_segments_LR.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "10e89b4373ca82b9aa008416dbc6678ec2573a3d463e333e4d350f38af34d33f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
