{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1628219938536,
     "user": {
      "displayName": "Babandeep Singh",
      "photoUrl": "",
      "userId": "14171741079947983888"
     },
     "user_tz": -330
    },
    "id": "0iSAbUcTbLBd",
    "outputId": "527ff0b2-f33d-493c-9969-78bf51bd09fc"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(r\"./utils\")\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "COLAB = False\n",
    "SAMPLE = False\n",
    "DRY_RUN = False\n",
    "\n",
    "GROUP_NAME = \"whole_dataset\"\n",
    "MODEL_DICT = \\\n",
    "            {\"NN\": {'epochs': 25} , \n",
    "             \"LR\": {'max_iter': 100}\n",
    "            }\n",
    "SELF_REPORTED_COLS = \\\n",
    "           ['age',\n",
    "            'country_canada', \n",
    "            'country_united kingdom',\n",
    "            'country_united states',\n",
    "            'database_dating',\n",
    "            'database_fb',\n",
    "            'gender',\n",
    "           ]\n",
    "DATA_DROP_COLS = \\\n",
    "           ['Unnamed: 0', # index columns\n",
    "            'Unnamed: 0.1', # TODO: might need to change this for bigger dataset. ,\n",
    "            # 'pol',  # label column\n",
    "            # 'gender', # self reported and filtered already\n",
    "            # 'age', # self-reported  \n",
    "            # 'country', # self reported and filtered already\n",
    "            'userid', # index equivalent column \n",
    "            'pol_dat_us', # redundant columns with label\n",
    "            'pol_dat_ca', # redundant columns with label\n",
    "            'pol_dat_uk', # redundant columns with label\n",
    "            'pol_fb_us', # redundant columns with label\n",
    "            # 'database', # filtered already \n",
    "            # 'ethnicity.value' # filtered already\n",
    "            ]\n",
    "RESULTS_COLS = \\\n",
    "            [\"Group Name\", \n",
    "             \"Model\", \n",
    "             \"Feature Set\", \n",
    "             \"Test AUC\", \n",
    "             \"Test Accuracy\",\n",
    "            ]\n",
    "DATA_DIR = \"./data/full/\"\n",
    "RESULTS_DIR = \"./results/full/\"\n",
    "RESULTS_STATS_FILENAME = GROUP_NAME + '.csv'\n",
    "RESULTS_MODEL_FILENAME_PREFIX = GROUP_NAME\n",
    "\n",
    "if SAMPLE:\n",
    "  MODEL_DICT = \\\n",
    "            {\"NN\": {'epochs': 1} , \n",
    "             \"LR\": {'max_iter': 1}\n",
    "            }\n",
    "  DATA_DIR = \"./data/sample/\"\n",
    "  RESULTS_DIR = \"./results/sample/\"\n",
    "  DATA_SHAPE_0 = 31742\n",
    "  DATA_SHAPE_1 = 2092\n",
    "  \n",
    "logger.debug(f\"Started the script for {GROUP_NAME}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "    \n",
    "  #TODO: untested for COLAB == True, more might be needed here\n",
    "  DATA_DIR = \"/content/drive/Shareddrives/Facial Recognition/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "\n",
    "folders = os.listdir(DATA_DIR)\n",
    "dataframes = []\n",
    "for folder in tqdm(folders):\n",
    "  logger.debug(f\"In folder {folder}.\")\n",
    "  csv_files = os.listdir(DATA_DIR + folder)\n",
    "  for csv in csv_files:\n",
    "    if '.csv' in csv:\n",
    "      logger.debug(DATA_DIR + folder + \"/\" + csv)\n",
    "      df = pd.read_csv(DATA_DIR + folder + \"/\" + csv)\n",
    "      dataframes.append(df)\n",
    "\n",
    "data = pd.concat(dataframes, axis = 0)\n",
    "del df, dataframes\n",
    "logger.debug(f\"Data size is {data.shape}\")\n",
    "if SAMPLE: assert (data.shape[0] == DATA_SHAPE_0) and (data.shape[1] == DATA_SHAPE_1), \"Error: data shape is not correct!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "\n",
    "try:\n",
    "  data = data.drop(DATA_DROP_COLS, axis=1)\n",
    "except:\n",
    "  pass\n",
    "data = utils.get_clean_data(data)\n",
    "data_y = data['pol'].replace({\"liberal\": 1, \"conservative\": 0})\n",
    "data = data.drop('pol', axis = 1)\n",
    "all_features = data.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size = 0.2) \n",
    "del data, data_y\n",
    "# TODO: check reproducibility of splits so that additional metrics computed post-hoc\n",
    "# are consistent. See https://stackoverflow.com/questions/53182821/scikit-learn-train-test-split-not-reproducible\n",
    "\n",
    "\n",
    "# Define features for the various settings\n",
    "\n",
    "image_cols = list(map(str, range(1, 2049)))\n",
    "image_and_self_reported_cols = image_cols + SELF_REPORTED_COLS\n",
    "image_and_extracted_cols = [x for x in all_features if x not in SELF_REPORTED_COLS]\n",
    "image_and_self_reported_and_extracted_cols = all_features\n",
    "\n",
    "data_dict = {\n",
    "            \"Image Features\" : image_cols,\n",
    "            \"Image and Self Reported Features\" : image_and_self_reported_cols,\n",
    "            \"Image and Extracted Features\": image_and_extracted_cols,\n",
    "            \"Image, Self-reported and Extracted Features\": image_and_self_reported_and_extracted_cols\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1628219967786,
     "user": {
      "displayName": "Babandeep Singh",
      "photoUrl": "",
      "userId": "14171741079947983888"
     },
     "user_tz": -330
    },
    "id": "kdjY37aIRblE",
    "outputId": "966242ef-59b0-40d5-e701-0142c5349f86"
   },
   "outputs": [],
   "source": [
    "# Fit models and log results\n",
    "\n",
    "results = []\n",
    "for data_name, data_set_features in tqdm(data_dict.items()):\n",
    "  for model_name, model_params in MODEL_DICT.items():\n",
    "    try:\n",
    "      save_model_filepath = Path(RESULTS_DIR \\\n",
    "                       + RESULTS_MODEL_FILENAME_PREFIX \\\n",
    "                       + \"_\" + model_name \\\n",
    "                       + \"_\" + data_name.replace(\" \",\"_\").replace(\",\",\"\").replace(\"-\",\"_\") \\\n",
    "                       + '.mdl')\n",
    "      if save_model_filepath.is_file() or save_model_filepath.is_dir():\n",
    "        logger.debug(\"Model already exists. TODO: manually append results.\")\n",
    "      else:\n",
    "        logger.debug(f\"{GROUP_NAME}, {model_name}, {data_name}: model training started.\")\n",
    "        auc, acc, model = utils.fit_and_get_metrics(model_name,\n",
    "                                                    X_train[data_set_features],\n",
    "                                                    y_train,\n",
    "                                                    X_test[data_set_features],\n",
    "                                                    y_test,\n",
    "                                                    model_params = model_params,\n",
    "                                                    dry_run = DRY_RUN)\n",
    "        utils.save_model(model, model_name, save_model_filepath)\n",
    "        results.append([GROUP_NAME, model_name, data_name, auc, acc])\n",
    "        logger.debug(f\"{GROUP_NAME}, {model_name}, {data_name}: model training ended. AUC: {auc}, accuracy: {acc}\")\n",
    "    except:\n",
    "      logger.error(f\"{GROUP_NAME}, {model_name}, {data_name}: Error occured!\")\n",
    "\n",
    "save_results_filepath = Path(RESULTS_DIR + RESULTS_STATS_FILENAME)\n",
    "if save_results_filepath.is_file() is False:\n",
    "  utils.save_results(results_array = results, \n",
    "                     location = save_results_filepath,\n",
    "                     columns = RESULTS_COLS)\n",
    "else:\n",
    "  logger.debug(\"IMPORTANT: Results NOT SAVED. Save the list manually!\")\n",
    "  if len(results) > 0:\n",
    "    print(pd.DataFrame(results,columns = RESULTS_COLS))\n",
    "logger.debug(f\"Script for {GROUP_NAME} finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Whole_Data_NN.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "10e89b4373ca82b9aa008416dbc6678ec2573a3d463e333e4d350f38af34d33f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
