{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "# local imports\n",
    "sys.path.append(r\"./utils\")\n",
    "from utils import utils\n",
    "\n",
    "random.seed(1234)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "COLAB = False\n",
    "DEBUG = True\n",
    "DATA_DIR = \"./data/full/\"\n",
    "results_file_loc = \"results/ethnicity comparison/segment_results.csv\"\n",
    "\n",
    "if DEBUG:\n",
    "    DATA_DIR = \"./data/sample/\"\n",
    "\n",
    "DATA_DROP_COLS = \\\n",
    "           ['Unnamed: 0', # index columns\n",
    "           'Unnamed: 0.1', # TODO might need to change this for bigger dataset. \n",
    "            'gender', # self reported and filtered already\n",
    "            'country', # self reported and filtered already\n",
    "            'userid', # index equivalent column \n",
    "            'pol_dat_us', # redundant columns with label\n",
    "            'pol_dat_ca', # redundant columns with label\n",
    "            'pol_dat_uk', # redundant columns with label\n",
    "            'pol_fb_us', # redundant columns with label\n",
    "            'database', # filtered already \n",
    "            # 'ethnicity.value' # filtered already\n",
    "            ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "    \n",
    "  #TODO: untested for COLAB == True, more might be needed here\n",
    "  DATA_DIR = \"/content/drive/Shareddrives/Facial Recognition/data/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# List of data file paths\n",
    "\n",
    "folders = os.listdir(DATA_DIR)\n",
    "dataset_paths = []\n",
    "results = []\n",
    "problematic_data = []\n",
    "for folder in tqdm(folders):\n",
    "  \n",
    "  if folder != \"NO FILES\":\n",
    "    data = utils.get_segment_dataframe(segment_to_run = folder)\n",
    "\n",
    "    data = data.drop(DATA_DROP_COLS,axis=1)\n",
    "\n",
    "    for col in data.loc[:, data.isna().any()].columns:\n",
    "      data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "    data = data.drop(data.columns[data.isna().any()].tolist(), axis =1)\n",
    "\n",
    "    # cat_cols = data.select_dtypes(include=['object']).columns\n",
    "    # if len(cat_cols):\n",
    "    #   num_df = pd.get_dummies(data[list(cat_cols)])\n",
    "\n",
    "    # which group it is being processed on \n",
    "    group_name = folder\n",
    "    \n",
    "    only_image_cols = list(map(str, range(1,2049))) + ['pol']\n",
    "    image_self_reported = only_image_cols + ['age']\n",
    "\n",
    "    \n",
    "    try:\n",
    "      dataframe_dict = {\n",
    "      \"Only Image Features\" : data[only_image_cols],\n",
    "      \"Image and Self Reported Features\" : data[image_self_reported],\n",
    "      \"Image and extracted Features\":data.drop(\"age\",axis = 1),\n",
    "      \"Image, Self-reported and Extracted Features\": data\n",
    "    }\n",
    "    \n",
    "      for data_name, data_set in dataframe_dict.items():\n",
    "        for model_name in [\"NN\",\"LR\"]:\n",
    "          auc, acc = utils.fit_and_get_metrics(data_set, model_name)\n",
    "          results.append([group_name,model_name,data_name,auc,acc])\n",
    "    except:\n",
    "      problematic_data.append([group_name]) # DEBUG to check if the dataframe is off somewhere. \n",
    "      \n",
    "  # break\n",
    "results_df = pd.DataFrame(results, columns = [\"Group_Name\",\"Model\",\"feature_set\",\"Test AUC\",\"Test ACC\"])\n",
    "\n",
    "results_df.to_csv(results_file_loc, index=False)\n",
    "print(\" Segment Results Saved !!\")\n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UK_0_dating\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "10e89b4373ca82b9aa008416dbc6678ec2573a3d463e333e4d350f38af34d33f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}